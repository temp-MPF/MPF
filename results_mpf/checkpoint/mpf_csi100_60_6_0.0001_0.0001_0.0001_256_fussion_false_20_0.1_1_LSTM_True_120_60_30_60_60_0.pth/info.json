{"config": {"model_config": {"input_size": 6, "hidden_size": 64, "num_layers": 2, "use_attn": true, "dropout": 0.1}, "tra_config": {"num_states": 1, "hidden_size": 32, "tau": 1.0, "src_info": "LR_TPE"}, "lr": 0.0001, "n_epochs": 500, "early_stop": 20, "smooth_steps": 5, "max_steps_per_epoch": 100, "lamb": 2.0, "rho": 0.99, "seed": 10000, "logdir": "./results_mpf/checkpoint/mpf_csi100_60_6_0.0001_0.0001_0.0001_256_fussion_false_20_0.1_1_LSTM_True_120_60_30_60_60_0.pth"}, "best_eval_metric": -0.0856673344953421, "metric": {"MSE": 0.15622928410561956, "MAE": 0.31657287153135505, "IC": 0.061796636171920695, "ICIR": 0.36041491766433437}}